{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b65a2d3-9f07-4153-86ed-9e0ba2138b09",
   "metadata": {},
   "source": [
    "These finetuning steps are based on the tutorial linked here: https://medium.com/nlplanet/bert-finetuning-with-hugging-face-and-training-visualizations-with-tensorboard-46368a57fc97 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28533e1c-d759-4782-aaf3-8ed6390c0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjkov\\miniforge3\\envs\\ml\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cca980d-ab51-479a-ab0a-3723dad829b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scraper.hf_dataframe()\n",
    "    \n",
    "qa = df[[\"question\",\"answer\"]]\n",
    "    \n",
    "qa_clean = qa.map(scraper.cleaner)\n",
    "        \n",
    "#occ_dict = scraper.occ_dict_maker(qa_clean,'question')\n",
    "    \n",
    "basket, word_dict  = scraper.create_basket('word_occurences.csv',20,1000)\n",
    "\n",
    "ans_list, ans_dict  = scraper.create_basket('Answer_occurences.csv',10,20000)\n",
    "\n",
    "    #scraper.find_good_questions(qa_clean, ans_list, 'good_questions.csv')\n",
    "\n",
    "good_qs = scraper.retrieve_good_qs('good_questions.csv')\n",
    "\n",
    "    #print(good_qs)\n",
    "    \n",
    "    #print(datetime.now())\n",
    "count = 1\n",
    "X_list = []\n",
    "y_list = []\n",
    "    \n",
    "    #print (len(basket))\n",
    "    #print(len(ans_list))\n",
    "\n",
    "num_qs = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e76481-77af-485d-a5f1-6f5ed2fe5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#goes through each question and makes an X vector using one hot encoding and a Y vector, which has a number represent the answer\n",
    "for i in good_qs[0:num_qs]:\n",
    "        \n",
    "    tempVector = np.zeros(len(basket)).tolist()\n",
    "    for word in qa_clean.loc[int(i),\"question\"].split():\n",
    "            #print(word)\n",
    "        if word in basket:\n",
    "            tempVector[basket.index(word)] = 1\n",
    "                \n",
    "    X_list.append(tempVector)\n",
    "    y_list.append(ans_list.index(qa_clean.loc[int(i),\"answer\"]))\n",
    "        #print(count)\n",
    "        #count+=1\n",
    "       \n",
    "X = np.array(X_list)\n",
    "y = np.array(y_list)\n",
    "    \n",
    "    #for ans in y:\n",
    "        #print(ans_list[ans])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53479b74-ce6b-4690-aaa3-7ae9fb5b32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "#finish preprocessing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9b98b-de43-45a8-a0fd-63056b00d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e7a76-9827-429e-b327-2abbb5c68453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out tensorboard setup here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d0248-6d24-4e89-af0e-385e036b670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert finetuning here\n",
    "#experiment with different parameters here\n",
    "args = TrainingArguments(output_dir=model_output_dir, evaluation_strategy=\"steps\", eval_steps=50, logging_strategy=\"steps\", logging_steps=50,\n",
    "                         save_strategy=\"steps\", save_steps = 200, learning rate = 5e-5, num_train_epochs=1, load_best_model_at_end=True, metric_for_best_model=\"accuracy\",\n",
    "                         report_to=\"tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d47f0-7da5-4595-bdf2-409c9993abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass to trainer object, in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eccaf0-8ae6-483a-8923-9e876a87fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the metrics (accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
